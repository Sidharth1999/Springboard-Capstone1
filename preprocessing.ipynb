{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python371jvsc74a57bd0597be375a0af02eb3c3d3d6fe8c370a08fb7e001d2d85e430e9722657aedcaff",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "There are 2 major preprocessing steps to be performed before fitting any clustering models - <br>\n",
    "\n",
    "1)Removing outliers. Outliers can be very damaging in clustering algorithms like K-Means because even a single outlier can dramatically influence a cluster center. <br>\n",
    "\n",
    "2)Normalizing the data. Again, distance-sensitive algorithms like K-Means treat observations as vectors in a vector space with an implied inner product like Euclidean distance. This means all features need to have equal weights in feature vectors and that means normalizing their scales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/EDACollegeScorecard.csv')"
   ]
  },
  {
   "source": [
    "First, lets remove all observations with values in a column that are more than 3 standard deviations away from that column's mean - these are clearly outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7803\n2577\n"
     ]
    }
   ],
   "source": [
    "#Source: 'https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame'\n",
    "from scipy import stats\n",
    "\n",
    "print(len(df))\n",
    "numeric_df = df.select_dtypes(\"number\") #We may as well drop the INSTURL column, it does not add any meaningful value to the dataset\n",
    "new_df = numeric_df[(np.abs(stats.zscore(numeric_df)) < 3).all(axis=1)]\n",
    "print(len(new_df))"
   ]
  },
  {
   "source": [
    "That seems to drop way too much data, more than half. Perhaps we should be more sparing about our standard deviation threshold ..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7803\n",
      "6295\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "numeric_df = df.select_dtypes(\"number\") #We may as well drop the INSTURL column, it does not add any meaningful value to the dataset\n",
    "new_df = numeric_df[(np.abs(stats.zscore(numeric_df)) < 8).all(axis=1)]\n",
    "new_df.to_csv('./data/UnnormalizedCollegeScorecard.csv', index=False)\n",
    "print(len(new_df))"
   ]
  },
  {
   "source": [
    "We are again faced with a balancing act - retaining as much information as possible from observations, or eliminating potentially problematic observations that would mislead clustering models. The threshold of 8 SDs was again, an empirically chosen number that I believed didnt eliminate too much information but eliminated enough to make it worthwhile"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Around 1600 observations were dropped. It's a decent amount of data, but we still have more than 6000 observations to build a potentially more robust clustering model. If the models dont perform well, we can come back to this step and tweak the SD threshold. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now, we need to normalize the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            UNITID     OPEID    opeid6  HCM2  main  NUMBRANCH  CONTROL  \\\n",
       "0     0.000000e+00  0.000461  0.001188   0.0   1.0       0.00      0.0   \n",
       "1     5.603398e-07  0.226011  0.582669   0.0   1.0       0.00      0.5   \n",
       "2     8.923931e-07  0.000489  0.001261   0.0   1.0       0.00      0.0   \n",
       "3     2.013073e-06  0.000038  0.000097   0.0   1.0       0.00      0.0   \n",
       "4     3.092246e-06  0.000047  0.000121   0.0   1.0       0.00      0.0   \n",
       "...            ...       ...       ...   ...   ...        ...      ...   \n",
       "6290  9.999999e-01  0.005343  0.013772   0.0   0.0       0.05      0.0   \n",
       "6291  9.999999e-01  0.005342  0.013772   0.0   0.0       0.05      0.0   \n",
       "6292  1.000000e+00  0.005343  0.013772   0.0   0.0       0.05      0.0   \n",
       "6293  1.000000e+00  0.005342  0.013772   0.0   1.0       0.05      0.0   \n",
       "6294  1.000000e+00  0.005342  0.013772   0.0   0.0       0.05      0.0   \n",
       "\n",
       "       st_fips  region   LOCALE  ...  LO_INC_RPY_3YR_RT_SUPP  \\\n",
       "0     0.000000     0.5  0.03125  ...                0.711863   \n",
       "1     0.000000     0.5  0.03125  ...                0.579620   \n",
       "2     0.000000     0.5  0.03125  ...                0.708883   \n",
       "3     0.000000     0.5  0.65625  ...                0.324754   \n",
       "4     0.000000     0.5  0.62500  ...                0.697118   \n",
       "...        ...     ...      ...  ...                     ...   \n",
       "6290  0.155844     0.5  0.31250  ...                0.394902   \n",
       "6291  0.155844     0.5  0.31250  ...                0.394902   \n",
       "6292  0.155844     0.5  0.31250  ...                0.394902   \n",
       "6293  0.155844     0.5  0.31250  ...                0.394902   \n",
       "6294  0.155844     0.5  0.31250  ...                0.394902   \n",
       "\n",
       "      MD_INC_RPY_3YR_RT_SUPP  HI_INC_RPY_3YR_RT_SUPP  DEP_RPY_3YR_RT_SUPP  \\\n",
       "0                   0.730729                0.751029             0.753725   \n",
       "1                   0.659221                0.677674             0.611111   \n",
       "2                   0.794698                0.797386             0.788247   \n",
       "3                   0.505528                0.662853             0.501976   \n",
       "4                   0.763222                0.857456             0.877229   \n",
       "...                      ...                     ...                  ...   \n",
       "6290                0.461457                0.452632             0.451434   \n",
       "6291                0.461457                0.452632             0.451434   \n",
       "6292                0.461457                0.452632             0.451434   \n",
       "6293                0.461457                0.452632             0.451434   \n",
       "6294                0.461457                0.452632             0.451434   \n",
       "\n",
       "      PELL_RPY_3YR_RT_SUPP  NOPELL_RPY_3YR_RT_SUPP  FEMALE_RPY_3YR_RT_SUPP  \\\n",
       "0                 0.720400                0.760188                0.745171   \n",
       "1                 0.583138                0.736207                0.585495   \n",
       "2                 0.726713                0.825786                0.753531   \n",
       "3                 0.342870                0.663019                0.388141   \n",
       "4                 0.724479                0.792340                0.735767   \n",
       "...                    ...                     ...                     ...   \n",
       "6290              0.402464                0.540125                0.457405   \n",
       "6291              0.402464                0.540125                0.457405   \n",
       "6292              0.402464                0.540125                0.457405   \n",
       "6293              0.402464                0.540125                0.457405   \n",
       "6294              0.402464                0.540125                0.457405   \n",
       "\n",
       "      MALE_RPY_3YR_RT_SUPP  FIRSTGEN_RPY_3YR_RT_SUPP  \\\n",
       "0                 0.744139                  0.736720   \n",
       "1                 0.672211                  0.610722   \n",
       "2                 0.789209                  0.764913   \n",
       "3                 0.444554                  0.427713   \n",
       "4                 0.801658                  0.766960   \n",
       "...                    ...                       ...   \n",
       "6290              0.437099                  0.459960   \n",
       "6291              0.437099                  0.459960   \n",
       "6292              0.437099                  0.459960   \n",
       "6293              0.437099                  0.459960   \n",
       "6294              0.437099                  0.459960   \n",
       "\n",
       "      NOTFIRSTGEN_RPY_3YR_RT_SUPP  \n",
       "0                        0.759968  \n",
       "1                        0.642391  \n",
       "2                        0.787138  \n",
       "3                        0.425513  \n",
       "4                        0.757499  \n",
       "...                           ...  \n",
       "6290                     0.484178  \n",
       "6291                     0.484178  \n",
       "6292                     0.484178  \n",
       "6293                     0.484178  \n",
       "6294                     0.484178  \n",
       "\n",
       "[6295 rows x 221 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UNITID</th>\n      <th>OPEID</th>\n      <th>opeid6</th>\n      <th>HCM2</th>\n      <th>main</th>\n      <th>NUMBRANCH</th>\n      <th>CONTROL</th>\n      <th>st_fips</th>\n      <th>region</th>\n      <th>LOCALE</th>\n      <th>...</th>\n      <th>LO_INC_RPY_3YR_RT_SUPP</th>\n      <th>MD_INC_RPY_3YR_RT_SUPP</th>\n      <th>HI_INC_RPY_3YR_RT_SUPP</th>\n      <th>DEP_RPY_3YR_RT_SUPP</th>\n      <th>PELL_RPY_3YR_RT_SUPP</th>\n      <th>NOPELL_RPY_3YR_RT_SUPP</th>\n      <th>FEMALE_RPY_3YR_RT_SUPP</th>\n      <th>MALE_RPY_3YR_RT_SUPP</th>\n      <th>FIRSTGEN_RPY_3YR_RT_SUPP</th>\n      <th>NOTFIRSTGEN_RPY_3YR_RT_SUPP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000e+00</td>\n      <td>0.000461</td>\n      <td>0.001188</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.03125</td>\n      <td>...</td>\n      <td>0.711863</td>\n      <td>0.730729</td>\n      <td>0.751029</td>\n      <td>0.753725</td>\n      <td>0.720400</td>\n      <td>0.760188</td>\n      <td>0.745171</td>\n      <td>0.744139</td>\n      <td>0.736720</td>\n      <td>0.759968</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.603398e-07</td>\n      <td>0.226011</td>\n      <td>0.582669</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.03125</td>\n      <td>...</td>\n      <td>0.579620</td>\n      <td>0.659221</td>\n      <td>0.677674</td>\n      <td>0.611111</td>\n      <td>0.583138</td>\n      <td>0.736207</td>\n      <td>0.585495</td>\n      <td>0.672211</td>\n      <td>0.610722</td>\n      <td>0.642391</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.923931e-07</td>\n      <td>0.000489</td>\n      <td>0.001261</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.03125</td>\n      <td>...</td>\n      <td>0.708883</td>\n      <td>0.794698</td>\n      <td>0.797386</td>\n      <td>0.788247</td>\n      <td>0.726713</td>\n      <td>0.825786</td>\n      <td>0.753531</td>\n      <td>0.789209</td>\n      <td>0.764913</td>\n      <td>0.787138</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.013073e-06</td>\n      <td>0.000038</td>\n      <td>0.000097</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.65625</td>\n      <td>...</td>\n      <td>0.324754</td>\n      <td>0.505528</td>\n      <td>0.662853</td>\n      <td>0.501976</td>\n      <td>0.342870</td>\n      <td>0.663019</td>\n      <td>0.388141</td>\n      <td>0.444554</td>\n      <td>0.427713</td>\n      <td>0.425513</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.092246e-06</td>\n      <td>0.000047</td>\n      <td>0.000121</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.62500</td>\n      <td>...</td>\n      <td>0.697118</td>\n      <td>0.763222</td>\n      <td>0.857456</td>\n      <td>0.877229</td>\n      <td>0.724479</td>\n      <td>0.792340</td>\n      <td>0.735767</td>\n      <td>0.801658</td>\n      <td>0.766960</td>\n      <td>0.757499</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6290</th>\n      <td>9.999999e-01</td>\n      <td>0.005343</td>\n      <td>0.013772</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>0.155844</td>\n      <td>0.5</td>\n      <td>0.31250</td>\n      <td>...</td>\n      <td>0.394902</td>\n      <td>0.461457</td>\n      <td>0.452632</td>\n      <td>0.451434</td>\n      <td>0.402464</td>\n      <td>0.540125</td>\n      <td>0.457405</td>\n      <td>0.437099</td>\n      <td>0.459960</td>\n      <td>0.484178</td>\n    </tr>\n    <tr>\n      <th>6291</th>\n      <td>9.999999e-01</td>\n      <td>0.005342</td>\n      <td>0.013772</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>0.155844</td>\n      <td>0.5</td>\n      <td>0.31250</td>\n      <td>...</td>\n      <td>0.394902</td>\n      <td>0.461457</td>\n      <td>0.452632</td>\n      <td>0.451434</td>\n      <td>0.402464</td>\n      <td>0.540125</td>\n      <td>0.457405</td>\n      <td>0.437099</td>\n      <td>0.459960</td>\n      <td>0.484178</td>\n    </tr>\n    <tr>\n      <th>6292</th>\n      <td>1.000000e+00</td>\n      <td>0.005343</td>\n      <td>0.013772</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>0.155844</td>\n      <td>0.5</td>\n      <td>0.31250</td>\n      <td>...</td>\n      <td>0.394902</td>\n      <td>0.461457</td>\n      <td>0.452632</td>\n      <td>0.451434</td>\n      <td>0.402464</td>\n      <td>0.540125</td>\n      <td>0.457405</td>\n      <td>0.437099</td>\n      <td>0.459960</td>\n      <td>0.484178</td>\n    </tr>\n    <tr>\n      <th>6293</th>\n      <td>1.000000e+00</td>\n      <td>0.005342</td>\n      <td>0.013772</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>0.155844</td>\n      <td>0.5</td>\n      <td>0.31250</td>\n      <td>...</td>\n      <td>0.394902</td>\n      <td>0.461457</td>\n      <td>0.452632</td>\n      <td>0.451434</td>\n      <td>0.402464</td>\n      <td>0.540125</td>\n      <td>0.457405</td>\n      <td>0.437099</td>\n      <td>0.459960</td>\n      <td>0.484178</td>\n    </tr>\n    <tr>\n      <th>6294</th>\n      <td>1.000000e+00</td>\n      <td>0.005342</td>\n      <td>0.013772</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>0.155844</td>\n      <td>0.5</td>\n      <td>0.31250</td>\n      <td>...</td>\n      <td>0.394902</td>\n      <td>0.461457</td>\n      <td>0.452632</td>\n      <td>0.451434</td>\n      <td>0.402464</td>\n      <td>0.540125</td>\n      <td>0.457405</td>\n      <td>0.437099</td>\n      <td>0.459960</td>\n      <td>0.484178</td>\n    </tr>\n  </tbody>\n</table>\n<p>6295 rows Ã— 221 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = new_df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normalized_df = pd.DataFrame(x_scaled, columns=new_df.columns)\n",
    "normalized_df"
   ]
  },
  {
   "source": [
    "There is no reason to split this dataframe into a train and test set, since this is an unsupervised learning task. We want our clustering algorithms to use as much data as possible. So we are done with preprocessing, all's that's left is to save the df"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.to_csv('./data/PreprocessedCollegeScorecard.csv', index=False)"
   ]
  }
 ]
}